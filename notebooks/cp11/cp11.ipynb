{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Práctica #11 (Compilación)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta clase estaremos implementando un **generador de parsers LR(1)**. Procederemos de forma análoga a la clase anterior: primero implementaremos el mecanismo de construcción del **autómata LR(1)** y posteriormente heredaremos de **Shift-Reduce parser** para llenar la tabla **Action-Goto** de forma acorde.\n",
    "\n",
    "Comencemos por importar la clase `Grammar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabajaremos sobre el lenguaje de expresiones que usamos en la última conferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Terminals:\n",
      "\tE, A\n",
      "Terminals:\n",
      "\t=, +, int\n",
      "Productions:\n",
      "\t[E -> A = A, E -> int, A -> int + A, A -> int]\n"
     ]
    }
   ],
   "source": [
    "G = Grammar()\n",
    "E = G.NonTerminal('E', True)\n",
    "A = G.NonTerminal('A')\n",
    "equal, plus, num = G.Terminals('= + int')\n",
    "\n",
    "E %=  A + equal + A | num\n",
    "A %= num + plus + A | num\n",
    "\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items\n",
    "\n",
    "Usaremos la implementación de `Item` provista en `cmp.pycompiler` para modelar los items LR(1). Esta vez haremos uso del parámetro `lookaheads` que se especifica en el constructor de la clase `Item` para almacenar justamente los `lookaheads` de los items LR(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: E -> .A=A, {'$', '+'}\n"
     ]
    }
   ],
   "source": [
    "from cmp.pycompiler import Item\n",
    "\n",
    "item = Item(E.productions[0], 0, lookaheads=[G.EOF, plus])\n",
    "print('item:', item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se incluyó la función `Preview` a cada item. Esta devuelve todas las posibles cadenas que resultan de concatenar _\"lo que queda por leer del item tras saltarse `skip=1` símbolos\"_ con los posibles lookaheads. Esta función nos será útil, pues sabemos que el lookahead de los items LR(1) se obtiene de calcular el `first` de estas cadenas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item.Preview: ('=', 'A', '$')\n",
      "item.Preview: ('=', 'A', '+')\n"
     ]
    }
   ],
   "source": [
    "for preview in item.Preview():\n",
    "    print('item.Preview:', preview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clausura de un conjunto de items LR(1)\n",
    "\n",
    "Como primer paso para calcular la clausura, implementaremos la función `expand`. Esta recibe un item LR(1) y devuelve el conjunto de items que sugiere incluir (directamente) debido a la presencia de un `.` delante de un no terminal.\n",
    "\n",
    "> expand(\"$Y \\to \\alpha . X \\delta, c$\") = { \"$X \\to . \\beta, b$\" | $b \\in First(\\delta c)$ }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A -> .int+A, {'='}\n",
      "A -> .int, {'='}\n"
     ]
    }
   ],
   "source": [
    "from cmp.utils import ContainerSet\n",
    "from cmp.tools.parsing import compute_firsts, compute_local_first\n",
    "\n",
    "firsts = compute_firsts(G)\n",
    "firsts[G.EOF] = ContainerSet(G.EOF)\n",
    "\n",
    "def expand(item, G):\n",
    "  next_symbol = item.NextSymbol\n",
    "  if next_symbol is None or not next_symbol.IsNonTerminal:\n",
    "    return []\n",
    "    \n",
    "  lookaheads = ContainerSet()\n",
    "  firsts = compute_firsts(G)\n",
    "  firsts[G.EOF] = ContainerSet(G.EOF)\n",
    "  # Compute lookahead for child items\n",
    "  for preview in item.Preview():\n",
    "    lookaheads.update(compute_local_first(firsts,preview))        \n",
    "    \n",
    "  assert not lookaheads.contains_epsilon\n",
    "  # Build and return child items\n",
    "  output = []\n",
    "  for production in G.Productions:\n",
    "    if production.Left == next_symbol:\n",
    "      output.append(Item(production,0,lookaheads))\n",
    "  return output\n",
    "\n",
    "for x in expand(item, G) :\n",
    "  print(x)\n",
    "assert str(expand(item, G)) == \"[A -> .int+A, {'='}, A -> .int, {'='}]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como segundo paso, implementaremos la función `compress`. Esta recibe un conjunto de items LR(1) y devuelve el mismo conjunto pero en el que los items con mismo centro están unidos (se combinan los lookahead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{E -> .A=A, {'$', '+'}, E -> A.=A, {'+'}, E -> A=.A, {'$', '+'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compress(items):\n",
    "  centers = {}\n",
    "\n",
    "  for item in items:\n",
    "    center = item.Center()\n",
    "    try:\n",
    "      lookaheads = centers[center]\n",
    "    except KeyError:\n",
    "      centers[center] = lookaheads = set()\n",
    "    lookaheads.update(item.lookaheads)\n",
    "    \n",
    "  return { Item(x.production, x.pos, set(lookahead)) for x, lookahead in centers.items() }\n",
    "\n",
    "compress([\n",
    "  Item(E.productions[0], 0, lookaheads=(G.EOF,)),\n",
    "  Item(E.productions[0], 0, lookaheads=(plus,)),\n",
    "  Item(E.productions[0], 1, lookaheads=(plus,)),\n",
    "  Item(E.productions[0], 2, lookaheads=(plus,)),\n",
    "  Item(E.productions[0], 2, lookaheads=(plus,G.EOF)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clausura\n",
    "\n",
    "Finalmente implementaremos la función clausura de un conjunto de items LR(1). Recordemos que:\n",
    "\n",
    "> $CL(I) = I \\cup \\{ X \\rightarrow .\\beta, b\\}$ tales que:\n",
    "> - $Y \\rightarrow \\alpha .X \\delta, c \\in CL(I)$\n",
    "> - $b \\in First(\\delta c)$.\n",
    "\n",
    "Apoyándonos en las dos funciones anteriores, debería resultar relativamente simple. Como de costumbre para los algoritmos de este tipo, utilizaremos una técnica de punto fijo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A -> .int, {'$', '+', '='}\n",
      "A -> .int+A, {'$', '+', '='}\n",
      "E -> A=.A, {'$', '+'}\n",
      "E -> .A=A, {'$', '+'}\n"
     ]
    }
   ],
   "source": [
    "def closure_lr1(items, firsts):\n",
    "  closure = ContainerSet(*items)\n",
    "    \n",
    "  changed = True\n",
    "  while changed:\n",
    "    changed = False\n",
    "        \n",
    "    new_items = ContainerSet()\n",
    "    for item in closure:\n",
    "      for new_item in expand(item,G):\n",
    "        new_items.add(new_item)  \n",
    "\n",
    "    changed = closure.update(new_items)\n",
    "  return compress(closure)\n",
    "\n",
    "closure = closure_lr1([item, item.NextItem().NextItem()], firsts)\n",
    "for x in closure:\n",
    "  print(x)\n",
    "\n",
    "expected = {\n",
    "  Item(E.productions[0], 0, lookaheads=(plus, G.EOF)),\n",
    "  Item(E.productions[0], 2, lookaheads=(plus, G.EOF)),\n",
    "  Item(A.productions[0], 0, lookaheads=(plus, G.EOF, equal)),\n",
    "  Item(A.productions[1], 0, lookaheads=(plus, G.EOF, equal)),\n",
    "}\n",
    "assert closure == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goto\n",
    "\n",
    "Se provee la implementación de la función `goto(Ii, s)`. Recordemos que:\n",
    "\n",
    "> $Goto(I,X) = CL(\\{ Y \\rightarrow \\alpha X. \\beta, c | Y \\rightarrow \\alpha .X \\beta, c \\in I \\})$\n",
    "\n",
    "La función recibe como parámetro un conjunto de items y un símbolo, y devuelve el conjunto `goto(items, symbol)`. El método permite setear el parámentro `just_kernel=True` para calcular solamente el conjunto de items kernels en lugar de todo el conjunto de items. En caso contrario, se debe proveer el conjunto con los `firsts` de la gramática, puesto que serán usados al calcular la clausura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{E -> A.=A, {'$', '+'}}\n"
     ]
    }
   ],
   "source": [
    "def goto_lr1(items, symbol, G, just_kernel=False):\n",
    "  #assert just_kernel or firsts is not None, '`firsts` must be provided if `just_kernel=False`'\n",
    "  items = frozenset(item.NextItem() for item in items if item.NextSymbol == symbol)\n",
    "  return items if just_kernel else closure_lr1(items, G)\n",
    "\n",
    "goto = goto_lr1([item], A, G)\n",
    "print(goto)\n",
    "assert  goto == {\n",
    "  Item(E.productions[0], 1, lookaheads=(plus, G.EOF))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción del autómata LR(1)\n",
    "\n",
    "Implementemos el algoritmo para construir el autómata LR(1). Recordemos de conferencia que:\n",
    "- El estado inicial es la clausura del item **`S' -> .S, $`**.\n",
    "- Todos los estados son finales.\n",
    "- Las transiciones ocurren con terminales y no terminales.\n",
    "- La función de transición está dada por la función **goto**.\n",
    "    - `f(Ii, c) = Goto(Ii, c)`\n",
    "\n",
    "_**OJO:** Intente usar solo los items kernel al comparar los estados._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.automata import State, multiline_formatter\n",
    "\n",
    "def build_LR1_automaton(G):\n",
    "  assert len(G.startSymbol.productions) == 1, 'Grammar must be augmented'\n",
    "    \n",
    "  # firsts = compute_firsts(G)\n",
    "  # firsts[G.EOF] = ContainerSet(G.EOF)\n",
    "    \n",
    "  start_production = G.startSymbol.productions[0]\n",
    "  start_item = Item(start_production, 0, lookaheads=(G.EOF,))\n",
    "  start = frozenset([start_item])\n",
    "    \n",
    "  closure = closure_lr1(start, G)\n",
    "  automaton = State(frozenset(closure), True)\n",
    "    \n",
    "  pending = [ start ]\n",
    "  visited = { start: automaton }\n",
    "    \n",
    "  while pending:\n",
    "    current = pending.pop()\n",
    "    current_state = visited[current]\n",
    "        \n",
    "    for symbol in G.terminals + G.nonTerminals:\n",
    "      # Get/Build `next_state`\n",
    "      next_items = frozenset(goto_lr1(current_state.state,symbol,G))\n",
    "      if not next_items:\n",
    "        continue\n",
    "      try:\n",
    "        next_state = visited[next_items]\n",
    "      except KeyError:\n",
    "        visited[next_items] = State(next_items,True)\n",
    "        pending.append(next_items)\n",
    "        next_state = visited[next_items]\n",
    "            \n",
    "      current_state.add_transition(symbol.Name, next_state)\n",
    "    \n",
    "  automaton.set_formatter(multiline_formatter)\n",
    "  return automaton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que este autómata, a pesar de presentar diferencias con el autómata LR(0), continua reconociendo el lenguaje de los prefijos viables de una gramática: cadenas que pueden ocurrir en la pila durante el parseo de una cadena válida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({S' -> .E, {'$'}, E -> .A=A, {'$'}, E -> .int, {'$'}, A -> .int, {'='}, A -> .int+A, {'='}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automaton = build_LR1_automaton(G.AugmentedGrammar())\n",
    "\n",
    "assert automaton.recognize('E')\n",
    "assert automaton.recognize(['A','=','int'])\n",
    "assert automaton.recognize(['int','+','int','+','A'])\n",
    "\n",
    "assert not automaton.recognize(['int','+','A','+','int'])\n",
    "assert not automaton.recognize(['int','=','int'])\n",
    "\n",
    "automaton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser LR(1) canónico\n",
    "\n",
    "Reutilizaremos la implementación base de parser Shift-Reduce que terminamos en la clase anterior. Recordemos que esta clase se encarga de todo el algoritmo de parsing, dejando en mano de sus herederos la implementación concreta del método `_build_parsing_table` para llenar la tabla Acción-Goto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftReduceParser:\n",
    "  SHIFT = 'SHIFT'\n",
    "  REDUCE = 'REDUCE'\n",
    "  OK = 'OK'\n",
    "    \n",
    "  def __init__(self, G, verbose=False):\n",
    "    self.G = G\n",
    "    self.verbose = verbose\n",
    "    self.action = {}\n",
    "    self.goto = {}\n",
    "    self._build_parsing_table()\n",
    "    \n",
    "  def _build_parsing_table(self):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "  def __call__(self, w):\n",
    "    stack = [ 0 ]\n",
    "    cursor = 0\n",
    "    output = []\n",
    "        \n",
    "    while True:\n",
    "      state = stack[-1]\n",
    "      lookahead = w[cursor]\n",
    "\n",
    "      if self.verbose: \n",
    "        print(stack, '<---||--->', w[cursor:])\n",
    "                \n",
    "      action, tag = self.action[state, lookahead]      \n",
    "      match action:\n",
    "        case self.SHIFT:\n",
    "          stack.append(lookahead)\n",
    "          stack.append(tag)\n",
    "          cursor += 1\n",
    "        case self.REDUCE:\n",
    "          production = self.G.Productions[tag]\n",
    "          X, beta = production\n",
    "          for i in range(2 * len(beta)):\n",
    "            stack.pop()\n",
    "          l = stack[-1]\n",
    "          stack.append(X.Name)\n",
    "          stack.append(self.goto[l,X])\n",
    "          output.append(production)\n",
    "        case self.OK:\n",
    "          break\n",
    "        case _:\n",
    "          raise Exception\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cómo llena la tabla un parser LR(1)?\n",
    "\n",
    "- **Sea** \"$X \\to \\alpha .c \\omega, s$\" un item del estado $I_i$ y $Goto(I_i,c) = I_j$.  \n",
    "**Entonces** $ACTION[I_i,c] = `S_j`$.\n",
    "\n",
    "- **Sea** \"$X \\to \\alpha ., s$\" un item del estado $I_i$.  \n",
    "**Entonces** $ACTION[I_i,s] = `R_k`$ (producción `k` es $X \\to \\alpha$).\n",
    "\n",
    "- **Sea** $I_i$ el estado que contiene el item \"$S' \\to S., \\$$\" ($S'$ distinguido).  \n",
    "**Entonces** $ACTION[I_i,\\$] = `OK`$.\n",
    "\n",
    "- **Sea** \"$X \\to \\alpha .Y \\omega, s$\" item del estado $I_i$ y $Goto(I_i,Y) = I_j$.  \n",
    "**Entonces** $GOTO[I_i,Y] = j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR1Parser(ShiftReduceParser):\n",
    "  def _build_parsing_table(self):\n",
    "    G = self.G.AugmentedGrammar(True)\n",
    "        \n",
    "    automaton = build_LR1_automaton(G)\n",
    "    for i, node in enumerate(automaton):\n",
    "      if self.verbose: \n",
    "        print(i, '\\t', '\\n\\t '.join(str(x) for x in node.state), '\\n')\n",
    "      node.idx = i\n",
    "\n",
    "    for node in automaton:\n",
    "      idx = node.idx\n",
    "      for item in node.state:\n",
    "        # Fill `self.Action` and `self.Goto` according to `item`\n",
    "        X = item.production.Left\n",
    "        symbol = item.NextSymbol\n",
    "        if X == G.startSymbol and item.IsReduceItem:\n",
    "          self._register(self.action,(idx,G.EOF),(self.OK,0))\n",
    "        elif item.IsReduceItem:\n",
    "          k = self.G.Productions.index(item.production)\n",
    "          for s in item.lookaheads:                        \n",
    "            self._register(self.action,(idx,s),(self.REDUCE,k))\n",
    "        elif symbol.IsTerminal:\n",
    "          self._register(self.action,(idx,symbol),(self.SHIFT,node.transitions[symbol.Name][0].idx))\n",
    "        else:\n",
    "          self._register(self.goto,(idx,symbol),node.transitions[symbol.Name][0].idx)\n",
    "        \n",
    "  @staticmethod\n",
    "  def _register(table, key, value):\n",
    "    assert key not in table or table[key] == value, 'Shift-Reduce or Reduce-Reduce conflict!!!'\n",
    "    table[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando\n",
    "\n",
    "Construyamos un parser LR(1) para la gramática de expresiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t E -> .int, {'$'}\n",
      "\t S' -> .E, {'$'}\n",
      "\t E -> .A=A, {'$'}\n",
      "\t A -> .int, {'='}\n",
      "\t A -> .int+A, {'='} \n",
      "\n",
      "1 \t E -> int., {'$'}\n",
      "\t A -> int.+A, {'='}\n",
      "\t A -> int., {'='} \n",
      "\n",
      "2 \t A -> .int, {'='}\n",
      "\t A -> int+.A, {'='}\n",
      "\t A -> .int+A, {'='} \n",
      "\n",
      "3 \t A -> int.+A, {'='}\n",
      "\t A -> int., {'='} \n",
      "\n",
      "4 \t A -> int+A., {'='} \n",
      "\n",
      "5 \t S' -> E., {'$'} \n",
      "\n",
      "6 \t E -> A.=A, {'$'} \n",
      "\n",
      "7 \t A -> .int+A, {'$'}\n",
      "\t A -> .int, {'$'}\n",
      "\t E -> A=.A, {'$'} \n",
      "\n",
      "8 \t A -> int.+A, {'$'}\n",
      "\t A -> int., {'$'} \n",
      "\n",
      "9 \t A -> .int+A, {'$'}\n",
      "\t A -> .int, {'$'}\n",
      "\t A -> int+.A, {'$'} \n",
      "\n",
      "10 \t A -> int+A., {'$'} \n",
      "\n",
      "11 \t E -> A=A., {'$'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = LR1Parser(G, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tablas\n",
    "\n",
    "Para visualizar las tablas Action y Goto usaremos la clase `DataFrame` de `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_value\u001b[39m(value):\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "def encode_value(value):\n",
    "  try:\n",
    "    action, tag = value\n",
    "    if action == ShiftReduceParser.SHIFT:\n",
    "      return 'S' + str(tag)\n",
    "    elif action == ShiftReduceParser.REDUCE:\n",
    "      return repr(tag)\n",
    "    elif action ==  ShiftReduceParser.OK:\n",
    "      return action\n",
    "    else:\n",
    "      return value\n",
    "  except TypeError:\n",
    "    return value\n",
    "\n",
    "def table_to_dataframe(table):\n",
    "  d = {}\n",
    "  for (state, symbol), value in table.items():\n",
    "    value = encode_value(value)\n",
    "    try:\n",
    "      d[state][symbol] = value\n",
    "    except KeyError:\n",
    "      d[state] = { symbol: value }\n",
    "\n",
    "  return DataFrame.from_dict(d, orient='index', dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que:\n",
    "\n",
    "- Debe haber a lo sumo una opción en cada celda.\n",
    "\n",
    "- Deben aparecer todos los estados (salvo $I_0$) entre **ACTION** y **GOTO**.\n",
    "\n",
    "- Deben aparecer todas las producciones entre los $R_k$ de **ACTION**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>int</th>\n",
       "      <th>$</th>\n",
       "      <th>+</th>\n",
       "      <th>=</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>S2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>S9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    int    $    +    =\n",
       "0    S1  NaN  NaN  NaN\n",
       "2    S3  NaN  NaN  NaN\n",
       "7    S8  NaN  NaN  NaN\n",
       "9    S8  NaN  NaN  NaN\n",
       "1   NaN    1   S2    3\n",
       "5   NaN   OK  NaN  NaN\n",
       "8   NaN    3   S9  NaN\n",
       "10  NaN    2  NaN  NaN\n",
       "11  NaN    0  NaN  NaN\n",
       "3   NaN  NaN   S2    3\n",
       "4   NaN  NaN  NaN    2\n",
       "6   NaN  NaN  NaN   S7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     E   A\n",
       "0  5.0   6\n",
       "2  NaN   4\n",
       "7  NaN  11\n",
       "9  NaN  10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(table_to_dataframe(parser.action))\n",
    "display(table_to_dataframe(parser.goto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parseando ...\n",
    "\n",
    "Trabajemos sobre la cadena `int + int = int + int`. Si el parser está correctamente implementado deberíamos obtener una derivación extrema derecha en reverso que parta de la oración y llegue al símbolo distinguido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] <---||---> ['int', '+', 'int', '=', 'int', '+', 'int', '$']\n",
      "[0, 'int', 1] <---||---> ['+', 'int', '=', 'int', '+', 'int', '$']\n",
      "[0, 'int', 1, '+', 2] <---||---> ['int', '=', 'int', '+', 'int', '$']\n",
      "[0, 'int', 1, '+', 2, 'int', 3] <---||---> ['=', 'int', '+', 'int', '$']\n",
      "[0, 'int', 1, '+', 2, 'A', 4] <---||---> ['=', 'int', '+', 'int', '$']\n",
      "[0, 'A', 6] <---||---> ['=', 'int', '+', 'int', '$']\n",
      "[0, 'A', 6, '=', 7] <---||---> ['int', '+', 'int', '$']\n",
      "[0, 'A', 6, '=', 7, 'int', 8] <---||---> ['+', 'int', '$']\n",
      "[0, 'A', 6, '=', 7, 'int', 8, '+', 9] <---||---> ['int', '$']\n",
      "[0, 'A', 6, '=', 7, 'int', 8, '+', 9, 'int', 8] <---||---> ['$']\n",
      "[0, 'A', 6, '=', 7, 'int', 8, '+', 9, 'A', 10] <---||---> ['$']\n",
      "[0, 'A', 6, '=', 7, 'A', 11] <---||---> ['$']\n",
      "[0, 'E', 5] <---||---> ['$']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[A -> int, A -> int + A, A -> int, A -> int + A, E -> A = A]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derivation = parser([num, plus, num, equal, num, plus, num, G.EOF])\n",
    "\n",
    "assert str(derivation) == '[A -> int, A -> int + A, A -> int, A -> int + A, E -> A = A]'\n",
    "\n",
    "derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propuestas\n",
    "\n",
    "- Implemente un generador de parsers **LALR(1)**.\n",
    "- Complete el pipeline de evaluación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
